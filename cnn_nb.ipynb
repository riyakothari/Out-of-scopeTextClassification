{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    },
    "colab": {
      "name": "cnn.ipynb",
      "provenance": []
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "zfFreOfqKpMv"
      },
      "source": [
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "\n",
        "import torch"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9y_h6u0kKpND",
        "outputId": "9e31fb61-80e4-48eb-cad1-fd19fdd19291"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import json\n",
        "import random\n",
        "from sklearn import preprocessing\n",
        "from imblearn.under_sampling import RandomUnderSampler\n",
        "from sklearn.linear_model import SGDClassifier, LogisticRegression\n",
        "from sklearn.metrics import recall_score,precision_score,make_scorer\n",
        "from gensim.parsing.porter import PorterStemmer"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/externals/six.py:31: FutureWarning: The module is deprecated in version 0.21 and will be removed in version 0.23 since we've dropped support for Python 2.7. Please rely on the official version of six (https://pypi.org/project/six/).\n",
            "  \"(https://pypi.org/project/six/).\", FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:144: FutureWarning: The sklearn.neighbors.base module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.neighbors. Anything that cannot be imported from sklearn.neighbors is now part of the private API.\n",
            "  warnings.warn(message, FutureWarning)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nA6i9VNIKuFM",
        "outputId": "41801724-7b7d-4acb-d424-e3146b8a096c"
      },
      "source": [
        "from google.colab import drive\r\n",
        "drive.mount('/gdrive')\r\n",
        "%cd /gdrive/My\\ Drive/{'.//'}\r\n",
        "\r\n",
        "%cd LoyalAI\r\n",
        "%ls"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /gdrive\n",
            "/gdrive/My Drive\n",
            "/gdrive/My Drive/LoyalAI\n",
            "cnn.ipynb       LoyalAI.ipynb  model.pt  train.csv\n",
            "data_full.json  metrics.pt     test.csv  valid.csv\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GXtsbzBqKpNF"
      },
      "source": [
        "with open('data_full.json', 'r') as file:\n",
        "    all_data = json.load(file)\n",
        "#     print(len(dic))\n",
        "    \n",
        "oos_train_df = pd.DataFrame(all_data[\"oos_train\"])\n",
        "oos_val_df = pd.DataFrame(all_data[\"oos_val\"])\n",
        "oos_test_df = pd.DataFrame(all_data[\"oos_test\"])\n",
        "\n",
        "ins_train_df = pd.DataFrame(all_data[\"train\"])\n",
        "ins_val_df = pd.DataFrame(all_data[\"val\"])\n",
        "ins_test_df = pd.DataFrame(all_data[\"test\"])\n",
        "# ins_train_df.describe()"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XQKzdpXDKpNG"
      },
      "source": [
        "seed = 2\n",
        "random.seed(a=seed)\n",
        "arr = random.sample([i for i in range(150)], k=20)\n",
        "names = pd.unique(ins_train_df[1])\n",
        "picked = [names[i] for i in arr]\n",
        "# print(names)\n",
        "in_train = ins_train_df.loc[ins_train_df[1].isin(picked)]\n",
        "in_train.describe()\n",
        "\n",
        "in_test = ins_test_df.loc[ins_test_df[1].isin(picked)]\n",
        "in_val = ins_val_df.loc[ins_val_df[1].isin(picked)]"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TSqKtOuvKpNH"
      },
      "source": [
        "train = pd.concat([in_train, oos_train_df])\n",
        "test = pd.concat([in_test, oos_test_df])\n",
        "val = pd.concat([in_val, oos_val_df])"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UVwcsbJvKpNI"
      },
      "source": [
        "from gensim.utils import simple_preprocess\n",
        "train['token'] = [simple_preprocess(line, deacc=True) for line in train[0]] \n",
        "test['token'] = [simple_preprocess(line, deacc=True) for line in test[0]] \n",
        "val['token'] = [simple_preprocess(line, deacc=True) for line in val[0]] "
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "inwGIa0TKpNJ"
      },
      "source": [
        "in_train.head(10)\n",
        "input_features, y_train = train['token'], train[1]\n",
        "X_val, y_val = val['token'], val[1]\n",
        "X_test, y_test = test['token'], test[1]"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sfSDgIA4KpNK"
      },
      "source": [
        "porter_stemmer = PorterStemmer()\n",
        "new_input2 = pd.DataFrame(input_features).reset_index(drop=True)\n",
        "new_input2['stemmed_tokens'] = [[porter_stemmer.stem(word) for word in text] for text in new_input2['token']]\n",
        "# blah\n",
        "\n",
        "new_test2 = pd.DataFrame(X_test).reset_index(drop=True)\n",
        "new_test2['stemmed_tokens'] = [[porter_stemmer.stem(word) for word in text] for text in new_test2['token']]\n",
        "\n",
        "new_val2 = pd.DataFrame(X_val).reset_index(drop=True)\n",
        "new_val2['stemmed_tokens'] = [[porter_stemmer.stem(word) for word in text] for text in new_val2['token']]"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tb0AyL2wKpNL"
      },
      "source": [
        "train_features = [' '.join(first) for first in new_input2['stemmed_tokens']]\n",
        "# input_features[0]\n",
        "\n",
        "test_features = [' '.join(first) for first in new_test2['stemmed_tokens']]\n",
        "\n",
        "val_features = [' '.join(first) for first in new_val2['stemmed_tokens']]"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XmFXoJB8KpNL",
        "outputId": "08290fb8-a7ca-459c-db84-6621f16b8b2a"
      },
      "source": [
        "from gensim.models import Word2Vec\n",
        "import pickle\n",
        "size = 500\n",
        "window = 3\n",
        "min_count = 1\n",
        "workers = 1\n",
        "sg = 1\n",
        "OUTPUT_FOLDER = ''\n",
        "\n",
        "# Function to train word2vec model\n",
        "def make_word2vec_model(top_data_df_small, padding=True, sg=1, min_count=1, size=500, workers=3, window=3):\n",
        "    if  padding:\n",
        "        print(len(top_data_df_small))\n",
        "        temp_df = pd.Series(top_data_df_small).values\n",
        "        temp_df = list(temp_df)\n",
        "        temp_df.append(['pad'])\n",
        "        word2vec_file = OUTPUT_FOLDER + 'models/' + 'word2vec_' + str(size) + '_PAD.model'\n",
        "    else:\n",
        "        temp_df = top_data_df_small\n",
        "        word2vec_file = OUTPUT_FOLDER + 'models/' + 'word2vec_' + str(size) + '.model'\n",
        "    w2v_model = Word2Vec(temp_df, min_count = min_count, size = size, workers = workers, window = window, sg = sg)\n",
        "    with open(word2vec_file, \"wb\") as f:\n",
        "        pickle.dump(w2v_model, f)\n",
        "    return w2v_model, word2vec_file\n",
        "\n",
        "# Train Word2vec model\n",
        "w2vmodel, word2vec_file = make_word2vec_model(new_input2['stemmed_tokens'], padding=True, sg=sg, min_count=min_count, size=size, workers=workers, window=window)\n",
        "#new_input2['stemmed_tokens']\n"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2100\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "31NgF_2FKpNM"
      },
      "source": [
        "max_sen_len = new_input2['stemmed_tokens'].map(len).max()\n",
        "padding_idx = w2vmodel.wv.vocab['pad'].index\n",
        "def make_word2vec_vector_cnn(sentence):\n",
        "    padded_X = [padding_idx for i in range(max_sen_len)]\n",
        "    i = 0\n",
        "#     print(sentence)\n",
        "    for word in sentence.split(\" \"):\n",
        "        if word not in w2vmodel.wv.vocab:\n",
        "            padded_X[i] = 0\n",
        "            #print(word)\n",
        "        else:\n",
        "#             print(\"BLAH BLAH \",word, \" black sheep\")\n",
        "            padded_X[i] = w2vmodel.wv.vocab[word].index\n",
        "        i += 1\n",
        "    return torch.tensor(padded_X, dtype=torch.long, device=device).view(1, -1)"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mITF6_ZXKpNN"
      },
      "source": [
        "encoded_y = np.where(y_train!='oos', 0, 1)\n",
        "y_true_val = np.where(y_val!='oos', 0, 1)\n",
        "y_true_test = np.where(y_test!='oos', 0, 1)"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "huKNPfWWKpNO"
      },
      "source": [
        "device = 'cpu'\n",
        "def make_target(label):\n",
        "    if label == 0:\n",
        "        return torch.tensor([0], dtype=torch.long, device=device)\n",
        "    elif label == 1:\n",
        "        return torch.tensor([1], dtype=torch.long, device=device)"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YhswDrttKpNP"
      },
      "source": [
        "EMBEDDING_SIZE = 500\n",
        "NUM_FILTERS = 10\n",
        "import gensim\n",
        "\n",
        "class CnnTextClassifier(nn.Module):\n",
        "    def __init__(self, vocab_size, num_classes, window_sizes=(1,2,3,5)):\n",
        "        super(CnnTextClassifier, self).__init__()\n",
        "        w2vmodel = gensim.models.KeyedVectors.load(OUTPUT_FOLDER + 'models/' + 'word2vec_500_PAD.model')\n",
        "        weights = w2vmodel.wv\n",
        "        # With pretrained embeddings\n",
        "        self.embedding = nn.Embedding.from_pretrained(torch.FloatTensor(weights.vectors), padding_idx=w2vmodel.wv.vocab['pad'].index)\n",
        "        # Without pretrained embeddings\n",
        "        # self.embedding = nn.Embedding(vocab_size, EMBEDDING_SIZE)\n",
        "\n",
        "        self.convs = nn.ModuleList([\n",
        "                                   nn.Conv2d(1, NUM_FILTERS, [window_size, EMBEDDING_SIZE], padding=(window_size - 1, 0))\n",
        "                                   for window_size in window_sizes\n",
        "        ])\n",
        "\n",
        "        self.fc = nn.Linear(NUM_FILTERS * len(window_sizes), num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.embedding(x) # [B, T, E]\n",
        "\n",
        "        # Apply a convolution + max_pool layer for each window size\n",
        "        x = torch.unsqueeze(x, 1)\n",
        "        xs = []\n",
        "        for conv in self.convs:\n",
        "            x2 = torch.tanh(conv(x))\n",
        "            x2 = torch.squeeze(x2, -1)\n",
        "            #print(\"x2\",x2.shape)\n",
        "            x2 = F.max_pool1d(x2, x2.size(2))\n",
        "            xs.append(x2)\n",
        "        x = torch.cat(xs, 2)\n",
        "\n",
        "        # FC\n",
        "        x = x.view(x.size(0), -1)\n",
        "        logits = self.fc(x)\n",
        "\n",
        "        probs = F.softmax(logits, dim = 1)\n",
        "\n",
        "        return probs"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        },
        "id": "gC-k5DJpKpNQ",
        "outputId": "d4600fa3-eb45-47c6-8819-924e5c0b9c2c"
      },
      "source": [
        "sdf = pd.DataFrame(train_features,\n",
        "                         columns=['stemmed_tokens'])\n",
        "# sdf = train_features #new_input2['stemmed_tokens']\n",
        "# sdf.head()\n",
        "\n",
        "sdf_test = pd.DataFrame(test_features,\n",
        "                         columns=['stemmed_tokens'])\n",
        "# sdf_test['stemmed_tokens'] = test_features #new_test2['stemmed_tokens']\n",
        "sdf_test.head()\n",
        "\n",
        "sdf_val = pd.DataFrame(val_features,\n",
        "                         columns=['stemmed_tokens'])\n",
        "# sdf_val['stemmed_tokens'] = val_features #new_val2['stemmed_tokens']\n",
        "sdf_val.head()"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>stemmed_tokens</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>is travel to franc safe</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>is franc safe to travel to</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>need to know is travel to franc safe</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>can travel to franc as far as safeti goe</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>can safe travel to franc or is it danger</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                             stemmed_tokens\n",
              "0                   is travel to franc safe\n",
              "1                is franc safe to travel to\n",
              "2      need to know is travel to franc safe\n",
              "3  can travel to franc as far as safeti goe\n",
              "4  can safe travel to franc or is it danger"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0leodCR-KpNT",
        "outputId": "49ca72c1-788d-4b85-f258-cada1a82706d"
      },
      "source": [
        "from imblearn.under_sampling import RandomUnderSampler\n",
        "from imblearn.over_sampling import RandomOverSampler\n",
        "oversample = RandomOverSampler(sampling_strategy='minority')\n",
        "undersample = RandomUnderSampler(sampling_strategy='majority')\n",
        "# fit and apply the transform\n",
        "X_under, y_under = undersample.fit_resample(sdf, encoded_y)\n",
        "X_over, y_over = oversample.fit_resample(sdf, encoded_y)"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DBtKPDp3KpNU"
      },
      "source": [
        "X_over = pd.DataFrame(X_over, columns=['stemmed_tokens'])\n",
        "X_under = pd.DataFrame(X_under, columns=['stemmed_tokens'])\n",
        "# X_over, X_under"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wTP_pWcwKpNV",
        "outputId": "a665ba82-e712-4857-8416-7c54787e2ef7"
      },
      "source": [
        "NUM_CLASSES = 2\n",
        "VOCAB_SIZE = len(w2vmodel.wv.vocab)\n",
        "device = 'cpu'\n",
        "cnn_model = CnnTextClassifier(vocab_size=VOCAB_SIZE, num_classes=NUM_CLASSES)\n",
        "cnn_model.to(device)\n",
        "loss_function = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(cnn_model.parameters(), lr=0.01)\n",
        "num_epochs = 30\n",
        "\n",
        "# Open the file for writing loss\n",
        "loss_file_name = OUTPUT_FOLDER +  'plots/' + 'cnn_class_big_loss_with_padding.csv'\n",
        "f = open(loss_file_name,'w')\n",
        "f.write('iter, loss')\n",
        "f.write('\\n')\n",
        "losses = []\n",
        "cnn_model.train()\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    print(\"Epoch\" + str(epoch + 1))\n",
        "    train_loss = 0\n",
        "    for index, row in X_under.iterrows(): #sdf\n",
        "        # Clearing the accumulated gradients\n",
        "        cnn_model.zero_grad()\n",
        "\n",
        "        # Make the bag of words vector for stemmed tokens \n",
        "        bow_vec = make_word2vec_vector_cnn(row['stemmed_tokens']) #0\n",
        "       \n",
        "        # Forward pass to get output\n",
        "        probs = cnn_model(bow_vec)\n",
        "#         print(probs, target)\n",
        "        # Get the target label\n",
        "        target = make_target(y_over[index]) #encoded_y\n",
        "\n",
        "        # Calculate Loss: softmax --> cross entropy loss\n",
        "        loss = loss_function(probs, target)\n",
        "        train_loss += loss.item()\n",
        "\n",
        "        # Getting gradients w.r.t. parameters\n",
        "        loss.backward()\n",
        "\n",
        "        # Updating parameters\n",
        "        optimizer.step()\n",
        "\n",
        "\n",
        "    # if index == 0:\n",
        "    #     continue\n",
        "    print(\"Epoch ran :\"+ str(epoch+1))\n",
        "    f.write(str((epoch+1)) + \",\" + str(train_loss / len(sdf)))\n",
        "    f.write('\\n')\n",
        "    train_loss = 0\n",
        "\n",
        "torch.save(cnn_model, OUTPUT_FOLDER + 'cnn_big_model_500_with_padding2.pth')\n",
        "\n",
        "f.close()\n",
        "print(\"Input vector\")\n",
        "print(bow_vec.cpu().numpy())\n",
        "print(\"Probs\")\n",
        "print(probs)\n",
        "# print(torch.argmax(probs, dim=1).cpu().numpy()[0])"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch1\n",
            "Epoch ran :1\n",
            "Epoch2\n",
            "Epoch ran :2\n",
            "Epoch3\n",
            "Epoch ran :3\n",
            "Epoch4\n",
            "Epoch ran :4\n",
            "Epoch5\n",
            "Epoch ran :5\n",
            "Epoch6\n",
            "Epoch ran :6\n",
            "Epoch7\n",
            "Epoch ran :7\n",
            "Epoch8\n",
            "Epoch ran :8\n",
            "Epoch9\n",
            "Epoch ran :9\n",
            "Epoch10\n",
            "Epoch ran :10\n",
            "Epoch11\n",
            "Epoch ran :11\n",
            "Epoch12\n",
            "Epoch ran :12\n",
            "Epoch13\n",
            "Epoch ran :13\n",
            "Epoch14\n",
            "Epoch ran :14\n",
            "Epoch15\n",
            "Epoch ran :15\n",
            "Epoch16\n",
            "Epoch ran :16\n",
            "Epoch17\n",
            "Epoch ran :17\n",
            "Epoch18\n",
            "Epoch ran :18\n",
            "Epoch19\n",
            "Epoch ran :19\n",
            "Epoch20\n",
            "Epoch ran :20\n",
            "Epoch21\n",
            "Epoch ran :21\n",
            "Epoch22\n",
            "Epoch ran :22\n",
            "Epoch23\n",
            "Epoch ran :23\n",
            "Epoch24\n",
            "Epoch ran :24\n",
            "Epoch25\n",
            "Epoch ran :25\n",
            "Epoch26\n",
            "Epoch ran :26\n",
            "Epoch27\n",
            "Epoch ran :27\n",
            "Epoch28\n",
            "Epoch ran :28\n",
            "Epoch29\n",
            "Epoch ran :29\n",
            "Epoch30\n",
            "Epoch ran :30\n",
            "Input vector\n",
            "[[   3    2  231 1292 1293   13   62 1294   33 1295 1295 1295 1295 1295\n",
            "  1295 1295 1295 1295 1295 1295 1295 1295]]\n",
            "Probs\n",
            "tensor([[1.0000e+00, 9.0761e-08]], grad_fn=<SoftmaxBackward>)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 488
        },
        "id": "3xr5RO0mKpNX",
        "outputId": "0566776b-2a8c-4265-cbe5-0d60b8fa21b1"
      },
      "source": [
        "from sklearn.metrics import classification_report\n",
        "bow_cnn_predictions = []\n",
        "original_lables_cnn_bow = []\n",
        "cnn_model.eval()\n",
        "loss_df = pd.read_csv(OUTPUT_FOLDER +'plots/'+ 'cnn_class_big_loss_with_padding.csv')\n",
        "print(loss_df.columns)\n",
        "# loss_df.plot('loss')\n",
        "with torch.no_grad():\n",
        "    for index, row in sdf_test.iterrows():\n",
        "        bow_vec = make_word2vec_vector_cnn(row['stemmed_tokens'])\n",
        "        probs = cnn_model(bow_vec)\n",
        "        _, predicted = torch.max(probs.data, 1)\n",
        "        bow_cnn_predictions.append(predicted.cpu().numpy()[0])\n",
        "        original_lables_cnn_bow.append(make_target(y_true_test[index]).cpu().numpy()[0])\n",
        "print(classification_report(original_lables_cnn_bow,bow_cnn_predictions))\n",
        "loss_file_name = OUTPUT_FOLDER +  'plots/' + 'cnn_class_big_loss_with_padding.csv'\n",
        "loss_df = pd.read_csv(loss_file_name)\n",
        "# print(loss_df.columns)\n",
        "plt_500_padding_30_epochs = loss_df[' loss'].plot()\n",
        "fig = plt_500_padding_30_epochs.get_figure()\n",
        "# fig.savefig(OUTPUT_FOLDER +'plots/' + 'loss_plt_500_padding_30_epochs.pdf\")\n",
        "\n"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Index(['iter', ' loss'], dtype='object')\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.38      1.00      0.55       600\n",
            "           1       0.00      0.00      0.00      1000\n",
            "\n",
            "    accuracy                           0.38      1600\n",
            "   macro avg       0.19      0.50      0.27      1600\n",
            "weighted avg       0.14      0.38      0.20      1600\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H1mcUutYKpNY"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FtWf9UJOKpNZ"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}